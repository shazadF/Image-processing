Script started on Thu 03 Nov 2016 06:22:29 BDT
]0;nabeel@nabeel-linux: ~/research/Forhad/neural_network/scriptsnabeel@nabeel-linux:~/research/Forhad/neural_network/scripts$ python cifar10_ica _nabeel.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 980 Ti (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5103)
/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.
  warnings.warn(warn)
X_train shape: (50000, 3, 32, 32)
50000 train samples
10000 test samples
(1000, 3, 3, 3)
(1000, 27)
Epoch 1/100
16s - loss: 1.8466 - acc: 0.3240 - val_loss: 1.5788 - val_acc: 0.4296
Epoch 2/100
16s - loss: 1.6925 - acc: 0.3805 - val_loss: 1.4757 - val_acc: 0.4727
Epoch 3/100
16s - loss: 1.6440 - acc: 0.4036 - val_loss: 1.4420 - val_acc: 0.4676
Epoch 4/100
16s - loss: 1.6091 - acc: 0.4187 - val_loss: 1.4119 - val_acc: 0.4911
Epoch 5/100
15s - loss: 1.5605 - acc: 0.4372 - val_loss: 1.3589 - val_acc: 0.5023
Epoch 6/100
16s - loss: 1.5255 - acc: 0.4542 - val_loss: 1.3407 - val_acc: 0.5192
Epoch 7/100
16s - loss: 1.4940 - acc: 0.4676 - val_loss: 1.2435 - val_acc: 0.5550
Epoch 8/100
16s - loss: 1.4609 - acc: 0.4776 - val_loss: 1.2227 - val_acc: 0.5644
Epoch 9/100
16s - loss: 1.4520 - acc: 0.4816 - val_loss: 1.2338 - val_acc: 0.5590
Epoch 10/100
16s - loss: 1.4292 - acc: 0.4930 - val_loss: 1.1884 - val_acc: 0.5783
Epoch 11/100
16s - loss: 1.4148 - acc: 0.4989 - val_loss: 1.1612 - val_acc: 0.5902
Epoch 12/100
16s - loss: 1.4086 - acc: 0.4996 - val_loss: 1.1865 - val_acc: 0.5914
Epoch 13/100
16s - loss: 1.3910 - acc: 0.5079 - val_loss: 1.1382 - val_acc: 0.5933
Epoch 14/100
16s - loss: 1.3918 - acc: 0.5079 - val_loss: 1.2259 - val_acc: 0.5610
Epoch 15/100
16s - loss: 1.3698 - acc: 0.5152 - val_loss: 1.1567 - val_acc: 0.5871
Epoch 16/100
15s - loss: 1.3589 - acc: 0.5227 - val_loss: 1.2986 - val_acc: 0.5543
Epoch 17/100
15s - loss: 1.3502 - acc: 0.5267 - val_loss: 1.1223 - val_acc: 0.6074
Epoch 18/100
15s - loss: 1.3643 - acc: 0.5216 - val_loss: 1.1436 - val_acc: 0.5928
Epoch 19/100
15s - loss: 1.3421 - acc: 0.5309 - val_loss: 1.1184 - val_acc: 0.6043
Epoch 20/100
15s - loss: 1.3410 - acc: 0.5303 - val_loss: 1.1111 - val_acc: 0.6047
Epoch 21/100
15s - loss: 1.3349 - acc: 0.5319 - val_loss: 1.1190 - val_acc: 0.5982
Epoch 22/100
15s - loss: 1.3235 - acc: 0.5365 - val_loss: 1.0959 - val_acc: 0.6127
Epoch 23/100
15s - loss: 1.3176 - acc: 0.5388 - val_loss: 1.0389 - val_acc: 0.6353
Epoch 24/100
15s - loss: 1.3166 - acc: 0.5391 - val_loss: 1.0921 - val_acc: 0.6168
Epoch 25/100
15s - loss: 1.3152 - acc: 0.5409 - val_loss: 1.0757 - val_acc: 0.6236
Epoch 26/100
15s - loss: 1.3094 - acc: 0.5433 - val_loss: 1.0727 - val_acc: 0.6238
Epoch 27/100
15s - loss: 1.3049 - acc: 0.5437 - val_loss: 1.0448 - val_acc: 0.6330
Epoch 28/100
15s - loss: 1.2988 - acc: 0.5481 - val_loss: 1.0775 - val_acc: 0.6231
Epoch 29/100
15s - loss: 1.3059 - acc: 0.5468 - val_loss: 1.0707 - val_acc: 0.6266
Epoch 30/100
15s - loss: 1.2901 - acc: 0.5543 - val_loss: 1.0602 - val_acc: 0.6303
Epoch 31/100
16s - loss: 1.2940 - acc: 0.5490 - val_loss: 1.0687 - val_acc: 0.6244
Epoch 32/100
16s - loss: 1.2830 - acc: 0.5517 - val_loss: 1.1120 - val_acc: 0.6147
Epoch 33/100
16s - loss: 1.2842 - acc: 0.5548 - val_loss: 1.0673 - val_acc: 0.6283
Epoch 34/100
16s - loss: 1.2698 - acc: 0.5545 - val_loss: 1.0265 - val_acc: 0.6460
Epoch 35/100
16s - loss: 1.2795 - acc: 0.5571 - val_loss: 1.0815 - val_acc: 0.6174
Epoch 36/100
16s - loss: 1.2694 - acc: 0.5598 - val_loss: 1.0359 - val_acc: 0.6295
Epoch 37/100
17s - loss: 1.2690 - acc: 0.5597 - val_loss: 1.0409 - val_acc: 0.6423
Epoch 38/100
16s - loss: 1.2663 - acc: 0.5604 - val_loss: 1.0556 - val_acc: 0.6283
Epoch 39/100
16s - loss: 1.2692 - acc: 0.5612 - val_loss: 1.0343 - val_acc: 0.6388
Epoch 40/100
16s - loss: 1.2643 - acc: 0.5616 - val_loss: 1.0546 - val_acc: 0.6398
Epoch 41/100
16s - loss: 1.2602 - acc: 0.5658 - val_loss: 1.0593 - val_acc: 0.6317
Epoch 42/100
16s - loss: 1.2542 - acc: 0.5657 - val_loss: 1.0649 - val_acc: 0.6252
Epoch 43/100
15s - loss: 1.2609 - acc: 0.5641 - val_loss: 1.0845 - val_acc: 0.6265
Epoch 44/100
15s - loss: 1.2526 - acc: 0.5669 - val_loss: 1.0445 - val_acc: 0.6425
Epoch 45/100
15s - loss: 1.2428 - acc: 0.5693 - val_loss: 1.0756 - val_acc: 0.6265
Epoch 46/100
15s - loss: 1.2450 - acc: 0.5703 - val_loss: 1.0063 - val_acc: 0.6505
Epoch 47/100
15s - loss: 1.2533 - acc: 0.5662 - val_loss: 1.0328 - val_acc: 0.6485
Epoch 48/100
15s - loss: 1.2389 - acc: 0.5722 - val_loss: 1.0366 - val_acc: 0.6385
Epoch 49/100
15s - loss: 1.2367 - acc: 0.5717 - val_loss: 1.0182 - val_acc: 0.6475
Epoch 50/100
15s - loss: 1.2354 - acc: 0.5693 - val_loss: 1.0422 - val_acc: 0.6395
Epoch 51/100
15s - loss: 1.2355 - acc: 0.5711 - val_loss: 1.0282 - val_acc: 0.6490
Epoch 52/100
15s - loss: 1.2327 - acc: 0.5709 - val_loss: 1.0056 - val_acc: 0.6496
Epoch 53/100
15s - loss: 1.2268 - acc: 0.5774 - val_loss: 0.9778 - val_acc: 0.6619
Epoch 54/100
15s - loss: 1.2274 - acc: 0.5747 - val_loss: 1.0007 - val_acc: 0.6605
Epoch 55/100
15s - loss: 1.2224 - acc: 0.5781 - val_loss: 1.0284 - val_acc: 0.6428
Epoch 56/100
15s - loss: 1.2274 - acc: 0.5774 - val_loss: 0.9874 - val_acc: 0.6611
Epoch 57/100
15s - loss: 1.2294 - acc: 0.5747 - val_loss: 1.0518 - val_acc: 0.6405
Epoch 58/100
15s - loss: 1.2205 - acc: 0.5784 - val_loss: 0.9824 - val_acc: 0.6575
Epoch 59/100
15s - loss: 1.2175 - acc: 0.5782 - val_loss: 1.0050 - val_acc: 0.6557
Epoch 60/100
16s - loss: 1.2119 - acc: 0.5815 - val_loss: 0.9519 - val_acc: 0.6758
Epoch 61/100
16s - loss: 1.2205 - acc: 0.5789 - val_loss: 1.0304 - val_acc: 0.6420
Epoch 62/100
16s - loss: 1.2129 - acc: 0.5790 - val_loss: 1.0293 - val_acc: 0.6510
Epoch 63/100
16s - loss: 1.2146 - acc: 0.5796 - val_loss: 0.9757 - val_acc: 0.6627
Epoch 64/100
15s - loss: 1.2103 - acc: 0.5812 - val_loss: 0.9877 - val_acc: 0.6644
Epoch 65/100
16s - loss: 1.2049 - acc: 0.5832 - val_loss: 1.0327 - val_acc: 0.6519
Epoch 66/100
16s - loss: 1.2105 - acc: 0.5817 - val_loss: 1.0047 - val_acc: 0.6539
Epoch 67/100
16s - loss: 1.2075 - acc: 0.5824 - val_loss: 0.9896 - val_acc: 0.6620
Epoch 68/100
16s - loss: 1.2132 - acc: 0.5822 - val_loss: 0.9688 - val_acc: 0.6714
Epoch 69/100
16s - loss: 1.2087 - acc: 0.5804 - val_loss: 0.9840 - val_acc: 0.6647
Epoch 70/100
16s - loss: 1.1981 - acc: 0.5854 - val_loss: 0.9511 - val_acc: 0.6755
Epoch 71/100
16s - loss: 1.1898 - acc: 0.5893 - val_loss: 1.0035 - val_acc: 0.6613
Epoch 72/100
15s - loss: 1.2046 - acc: 0.5820 - val_loss: 0.9823 - val_acc: 0.6605
Epoch 73/100
16s - loss: 1.1953 - acc: 0.5881 - val_loss: 0.9932 - val_acc: 0.6608
Epoch 74/100
16s - loss: 1.1987 - acc: 0.5887 - val_loss: 0.9662 - val_acc: 0.6701
Epoch 75/100
16s - loss: 1.1870 - acc: 0.5888 - val_loss: 1.0120 - val_acc: 0.6462
Epoch 76/100
16s - loss: 1.1991 - acc: 0.5877 - val_loss: 0.9708 - val_acc: 0.6679
Epoch 77/100
16s - loss: 1.1861 - acc: 0.5893 - val_loss: 0.9782 - val_acc: 0.6730
Epoch 78/100
16s - loss: 1.1924 - acc: 0.5895 - val_loss: 1.0052 - val_acc: 0.6577
Epoch 79/100
16s - loss: 1.1911 - acc: 0.5891 - val_loss: 0.9806 - val_acc: 0.6660
Epoch 80/100
15s - loss: 1.1866 - acc: 0.5908 - val_loss: 0.9581 - val_acc: 0.6755
Epoch 81/100
15s - loss: 1.1848 - acc: 0.5915 - val_loss: 0.9787 - val_acc: 0.6681
Epoch 82/100
15s - loss: 1.1877 - acc: 0.5913 - val_loss: 0.9583 - val_acc: 0.6711
Epoch 83/100
16s - loss: 1.1844 - acc: 0.5906 - val_loss: 0.9573 - val_acc: 0.6736
Epoch 84/100
16s - loss: 1.1836 - acc: 0.5928 - val_loss: 0.9768 - val_acc: 0.6684
Epoch 85/100
16s - loss: 1.1748 - acc: 0.5946 - val_loss: 0.9823 - val_acc: 0.6709
Epoch 86/100
16s - loss: 1.1769 - acc: 0.5928 - val_loss: 0.9801 - val_acc: 0.6672
Epoch 87/100
16s - loss: 1.1831 - acc: 0.5960 - val_loss: 1.0143 - val_acc: 0.6559
Epoch 88/100
16s - loss: 1.1780 - acc: 0.5931 - val_loss: 0.9549 - val_acc: 0.6777
Epoch 89/100
15s - loss: 1.1859 - acc: 0.5907 - val_loss: 0.9403 - val_acc: 0.6787
Epoch 90/100
15s - loss: 1.1770 - acc: 0.5946 - val_loss: 0.9796 - val_acc: 0.6676
Epoch 91/100
15s - loss: 1.1726 - acc: 0.5965 - val_loss: 0.9890 - val_acc: 0.6578
Epoch 92/100
15s - loss: 1.1669 - acc: 0.5994 - val_loss: 0.9366 - val_acc: 0.6780
Epoch 93/100
15s - loss: 1.1743 - acc: 0.5926 - val_loss: 1.0029 - val_acc: 0.6609
Epoch 94/100
15s - loss: 1.1648 - acc: 0.5986 - val_loss: 0.9755 - val_acc: 0.6637
Epoch 95/100
15s - loss: 1.1697 - acc: 0.5991 - val_loss: 0.9910 - val_acc: 0.6580
Epoch 96/100
15s - loss: 1.1684 - acc: 0.5981 - val_loss: 0.9329 - val_acc: 0.6847
Epoch 97/100
15s - loss: 1.1709 - acc: 0.5975 - val_loss: 0.9450 - val_acc: 0.6845
Epoch 98/100
15s - loss: 1.1616 - acc: 0.5995 - val_loss: 0.9337 - val_acc: 0.6820
Epoch 99/100
15s - loss: 1.1757 - acc: 0.5967 - val_loss: 0.9311 - val_acc: 0.6841
Epoch 100/100
15s - loss: 1.1643 - acc: 0.5985 - val_loss: 0.9331 - val_acc: 0.6830
]0;nabeel@nabeel-linux: ~/research/Forhad/neural_network/scriptsnabeel@nabeel-linux:~/research/Forhad/neural_network/scripts$ exit

Script done on Thu 03 Nov 2016 06:57:13 BDT
